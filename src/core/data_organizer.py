import logging
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
from typing import Optional

logger = logging.getLogger(__name__)


def adjust_dates_to_most_frequent(dates_series: pd.Series, date_format: str = "%Y-%m-%d") -> list:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Å–∞–º—É—é —á–∞—Å—Ç—É—é –¥–∞—Ç—É (—Å—á–∏—Ç–∞–µ—Ç –µ—ë "—Å–µ–≥–æ–¥–Ω—è").
    –ó–∞–º–µ–Ω—è–µ—Ç –≤—Å–µ –¥–∞—Ç—ã –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ ¬±1 –¥–µ–Ω—å –Ω–∞ —ç—Ç—É –¥–∞—Ç—É.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –¥–Ω–µ–≤–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤.
    
    Args:
        dates_series: Series —Å –¥–∞—Ç–∞–º–∏
        date_format: –§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞—Ç
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ datetime
    parsed_dates = pd.to_datetime(dates_series, errors='coerce')
    
    # –£–¥–∞–ª—è–µ–º NaN –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞
    valid_dates = parsed_dates.dropna()
    
    if valid_dates.empty:
        logger.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return dates_series.tolist()
    
    # –ù–∞—Ö–æ–¥–∏–º –¥–∞—Ç—É, –∫–æ—Ç–æ—Ä–∞—è –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—â–µ –≤—Å–µ–≥–æ (—ç—Ç–æ "—Å–µ–≥–æ–¥–Ω—è")
    most_frequent_date = valid_dates.mode()[0]
    most_frequent_date_str = most_frequent_date.strftime(date_format)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤—á–µ—Ä–∞ –∏ –∑–∞–≤—Ç—Ä–∞
    yesterday = most_frequent_date - timedelta(days=1)
    tomorrow = most_frequent_date + timedelta(days=1)
    
    # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    frequency = (valid_dates == most_frequent_date).sum()
    logger.info(f"–°–∞–º–∞—è —á–∞—Å—Ç–∞—è –¥–∞—Ç–∞ ('—Å–µ–≥–æ–¥–Ω—è'): {most_frequent_date_str} (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {frequency} —Ä–∞–∑ –∏–∑ {len(valid_dates)})")
    logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –∑–∞–º–µ–Ω—ã: {yesterday.strftime(date_format)} - {tomorrow.strftime(date_format)} ‚Üí {most_frequent_date_str}")
    
    # –ó–∞–º–µ–Ω—è–µ–º –≤—á–µ—Ä–∞, —Å–µ–≥–æ–¥–Ω—è –∏ –∑–∞–≤—Ç—Ä–∞ –Ω–∞ "—Å–µ–≥–æ–¥–Ω—è"
    corrected_dates = []
    replaced_count = 0
    
    for date_val in parsed_dates:
        if pd.isna(date_val):
            corrected_dates.append(None)
        elif yesterday <= date_val <= tomorrow:
            # –î–∞—Ç–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [–≤—á–µ—Ä–∞, —Å–µ–≥–æ–¥–Ω—è, –∑–∞–≤—Ç—Ä–∞]
            if date_val != most_frequent_date:
                corrected_dates.append(most_frequent_date_str)
                logger.debug(f"–î–∞—Ç–∞ {date_val.strftime(date_format)} –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {most_frequent_date_str}")
                replaced_count += 1
            else:
                corrected_dates.append(date_val.strftime(date_format))
        else:
            # –î–∞—Ç–∞ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            corrected_dates.append(date_val.strftime(date_format))
    
    if replaced_count > 0:
        logger.info(f"–ó–∞–º–µ–Ω–µ–Ω–æ –¥–∞—Ç: {replaced_count}")
    
    return corrected_dates


def adjust_weekly_dates(dates_series: pd.Series, date_format: str = "%Y-%m-%d") -> list:
    """
    –î–ª—è –Ω–µ–¥–µ–ª—å–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤:
    1. –ù–∞—Ö–æ–¥–∏—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
    2. –í—ã—á–∏—Å–ª—è–µ—Ç –Ω–∞—á–∞–ª–æ –Ω–µ–¥–µ–ª–∏ (max_date - 6 –¥–Ω–µ–π)
    3. –í—Å–µ –¥–∞—Ç—ã < –Ω–∞—á–∞–ª–∞ –Ω–µ–¥–µ–ª–∏ –∑–∞–º–µ–Ω—è–µ—Ç –Ω–∞ –Ω–∞—á–∞–ª–æ –Ω–µ–¥–µ–ª–∏
    
    Args:
        dates_series: Series —Å –¥–∞—Ç–∞–º–∏
        date_format: –§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞—Ç
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ datetime
    parsed_dates = pd.to_datetime(dates_series, errors='coerce')
    
    # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
    max_date = parsed_dates.max()
    
    if pd.isna(max_date):
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É")
        return dates_series.tolist()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–∞—á–∞–ª–æ –Ω–µ–¥–µ–ª–∏ (–º–∞–∫—Å - 6 –¥–Ω–µ–π)
    week_start = max_date - timedelta(days=6)
    
    max_date_str = max_date.strftime(date_format)
    week_start_str = week_start.strftime(date_format)
    
    logger.info(f"–ù–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç: {week_start_str} - {max_date_str}")
    
    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –¥–∞—Ç—ã –¥–æ –Ω–∞—á–∞–ª–∞ –Ω–µ–¥–µ–ª–∏ –Ω–∞ –Ω–∞—á–∞–ª–æ –Ω–µ–¥–µ–ª–∏
    corrected_dates = []
    for date_val in parsed_dates:
        if pd.isna(date_val):
            corrected_dates.append(None)
        elif date_val < week_start and date_val > week_start - timedelta(days=1):
            corrected_dates.append(week_start_str)
            logger.debug(f"–î–∞—Ç–∞ {date_val.strftime(date_format)} –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {week_start_str}")
        else:
            corrected_dates.append(date_val.strftime(date_format))
    
    return corrected_dates


def is_weekly_report(df: pd.DataFrame) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ç—á—ë—Ç –Ω–µ–¥–µ–ª—å–Ω—ã–º –∏–ª–∏ –¥–Ω–µ–≤–Ω—ã–º.
    """
    date_columns = ["–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏", "–î–∞—Ç–∞ —Å–ø–∏—Å–∞–Ω–∏—è", "–î–∞—Ç–∞"]
    
    for col in date_columns:
        if col in df.columns:
            unique_dates = df[col].nunique()
            # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 2 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç, —Å—á–∏—Ç–∞–µ–º –Ω–µ–¥–µ–ª—å–Ω—ã–º
            return unique_dates > 7
    
    return True


def classify_excel_file(file_path: Path) -> Optional[str]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø Excel —Ñ–∞–π–ª–∞ –ø–æ –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.
    
    Returns:
        'main_data' | 'reklama' | 'storage' | None
    """
    try:
        df = pd.read_excel(file_path, nrows=10)
        df.columns = df.columns.str.strip()
        
        if "ID –∫–∞–º–ø–∞–Ω–∏–∏" in df.columns and len(df.columns) < 10:
            return "reklama"
        elif "–ù–æ–º–µ—Ä —Å–∫–ª–∞–¥–∞" in df.columns and 20 < len(df.columns) < 30:
            return "storage"
        elif len(df.columns) > 50:
            return "main_data"
        else:
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_path.name}")
            return None
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path.name}: {e}")
        return None


def process_data_file(file_path: Path, output_path: Path) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—ã.
    """
    df = pd.read_excel(file_path)
    df.columns = df.columns.str.strip()
    
    if "–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏" not in df.columns:
        logger.warning(f"–ö–æ–ª–æ–Ω–∫–∞ '–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {file_path.name}")
        df.to_excel(output_path, index=False)
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
#    df = df.sort_values(by="–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏").reset_index(drop=True)
    
    is_weekly = is_weekly_report(df)
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {'–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ' if is_weekly else '–¥–Ω–µ–≤–Ω–æ–≥–æ'} –æ—Ç—á—ë—Ç–∞: {file_path.name}")
    
    if is_weekly:
        # –ù–µ–¥–µ–ª—å–Ω—ã–π: –≤—Å–µ –¥–∞—Ç—ã < (max_date - 6) ‚Üí (max_date - 6)
        df["–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏"] = adjust_weekly_dates(df["–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏"])
    else:
        # –î–Ω–µ–≤–Ω–æ–π: –≤—Å–µ –¥–∞—Ç—ã –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π ‚Üí –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        df["–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏"] = adjust_dates_to_most_frequent(df["–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏"])
    
    df.to_excel(output_path, index=False)
    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö: {file_path.name}")


def process_reklama_file(file_path: Path, output_path: Path) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —Å —Ä–µ–∫–ª–∞–º–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—ã.
    """
    df = pd.read_excel(file_path)
    df.columns = df.columns.str.strip()
    
    if "–î–∞—Ç–∞ —Å–ø–∏—Å–∞–Ω–∏—è" not in df.columns:
        logger.warning(f"–ö–æ–ª–æ–Ω–∫–∞ '–î–∞—Ç–∞ —Å–ø–∏—Å–∞–Ω–∏—è' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {file_path.name}")
        df.to_excel(output_path, index=False)
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    df = df.sort_values(by="–î–∞—Ç–∞ —Å–ø–∏—Å–∞–Ω–∏—è").reset_index(drop=True)
    
    is_weekly = is_weekly_report(df)
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {'–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ' if is_weekly else '–¥–Ω–µ–≤–Ω–æ–≥–æ'} –æ—Ç—á—ë—Ç–∞ —Ä–µ–∫–ª–∞–º—ã: {file_path.name}")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –æ—Ç–¥–µ–ª—å–Ω–æ
    dates_with_time = df["–î–∞—Ç–∞ —Å–ø–∏—Å–∞–Ω–∏—è"].astype(str)
    dates_only = []
    times_only = []
    
    for dt_str in dates_with_time:
        if pd.isna(dt_str) or dt_str == 'nan':
            dates_only.append(None)
            times_only.append("00:00")
        else:
            parts = dt_str.split()
            dates_only.append(parts[0] if len(parts) > 0 else None)
            times_only.append(parts[1] if len(parts) > 1 else "00:00")
    
    dates_series = pd.Series(dates_only)
    
    if is_weekly:
        # –ù–µ–¥–µ–ª—å–Ω—ã–π: –≤—Å–µ –¥–∞—Ç—ã < (max_date - 6) ‚Üí (max_date - 6)
        corrected_dates_only = adjust_weekly_dates(dates_series)
    else:
        # –î–Ω–µ–≤–Ω–æ–π: –≤—Å–µ –¥–∞—Ç—ã –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π ‚Üí –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        corrected_dates_only = adjust_dates_to_most_frequent(dates_series)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Å –≤—Ä–µ–º–µ–Ω–µ–º
    df["–î–∞—Ç–∞ —Å–ø–∏—Å–∞–Ω–∏—è"] = [
        f"{date} {time}" if date else None
        for date, time in zip(corrected_dates_only, times_only)
    ]
    
    df.to_excel(output_path, index=False)
    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª —Ä–µ–∫–ª–∞–º—ã: {file_path.name}")


def process_storage_file(file_path: Path, output_path: Path) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Å–∫–ª–∞–¥–µ, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—ã.
    """
    df = pd.read_excel(file_path)
    df.columns = df.columns.str.strip()
    
    if "–î–∞—Ç–∞" not in df.columns:
        logger.warning(f"–ö–æ–ª–æ–Ω–∫–∞ '–î–∞—Ç–∞' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {file_path.name}")
        df.to_excel(output_path, index=False)
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    df = df.sort_values(by="–î–∞—Ç–∞").reset_index(drop=True)
    
    is_weekly = is_weekly_report(df)
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {'–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ' if is_weekly else '–¥–Ω–µ–≤–Ω–æ–≥–æ'} –æ—Ç—á—ë—Ç–∞ —Å–∫–ª–∞–¥–∞: {file_path.name}")
    
    if is_weekly:
        # –ù–µ–¥–µ–ª—å–Ω—ã–π: –≤—Å–µ –¥–∞—Ç—ã < (max_date - 6) ‚Üí (max_date - 6)
        df["–î–∞—Ç–∞"] = adjust_weekly_dates(df["–î–∞—Ç–∞"])
    else:
        # –î–Ω–µ–≤–Ω–æ–π: –≤—Å–µ –¥–∞—Ç—ã –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π ‚Üí –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        df["–î–∞—Ç–∞"] = adjust_dates_to_most_frequent(df["–î–∞—Ç–∞"])
    
    df.to_excel(output_path, index=False)
    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª —Å–∫–ª–∞–¥–∞: {file_path.name}")
    

def organize_and_process_data(data_dir: Path = Path("data")) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç Excel —Ñ–∞–π–ª—ã –∏–∑ –∫–æ—Ä–Ω—è data/ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ –ø–æ–¥–ø–∞–ø–∫–∞–º.
    –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–¥–∞–ª—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã.
    
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
    data/
    ‚îú‚îÄ‚îÄ main_data/     (—Ñ–∞–π–ª—ã –ø—Ä–æ–¥–∞–∂ - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)
    ‚îú‚îÄ‚îÄ reklama/       (—Ñ–∞–π–ª—ã —Ä–µ–∫–ª–∞–º—ã - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)
    ‚îú‚îÄ‚îÄ storage/       (—Ñ–∞–π–ª—ã —Å–∫–ª–∞–¥–∞ - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)
    ‚îú‚îÄ‚îÄ file1.xlsx     (–∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã)
    ‚îî‚îÄ‚îÄ file2.xlsx
    """
    if not data_dir.exists():
        logger.error(f"–ü–∞–ø–∫–∞ {data_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ–¥–ø–∞–ø–æ–∫
    main_data_dir = data_dir / "main_data"
    reklama_dir = data_dir / "reklama"
    storage_dir = data_dir / "storage"
    
    for folder in [main_data_dir, reklama_dir, storage_dir]:
        folder.mkdir(parents=True, exist_ok=True)
    
    # –ò—â–µ–º –≤—Å–µ Excel —Ñ–∞–π–ª—ã –¢–û–õ–¨–ö–û –≤ –∫–æ—Ä–Ω–µ data/
    excel_files = [f for f in data_dir.glob("*.xlsx") if f.is_file()]
    
    if not excel_files:
        logger.warning(f"Excel —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫–æ—Ä–Ω–µ {data_dir}")
        return
    
    print(f"\nüìÇ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(excel_files)}\n")
    
    stats = {"main_data": 0, "reklama": 0, "storage": 0, "unknown": 0}
    processed_files = []  # —Å–ø–∏—Å–æ–∫ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    
    for file_path in excel_files:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã Excel
        if file_path.name.startswith("~$"):
            continue
        
        file_type = classify_excel_file(file_path)
        
        try:
            if file_type == "main_data":
                output_path = main_data_dir / file_path.name
                process_data_file(file_path, output_path)
                stats["main_data"] += 1
                processed_files.append(file_path)
                
            elif file_type == "reklama":
                output_path = reklama_dir / file_path.name
                process_reklama_file(file_path, output_path)
                stats["reklama"] += 1
                processed_files.append(file_path)
                
            elif file_type == "storage":
                output_path = storage_dir / file_path.name
                process_storage_file(file_path, output_path)
                stats["storage"] += 1
                processed_files.append(file_path)
                
            else:
                stats["unknown"] += 1
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path.name}: {e}")
    
    # –£–¥–∞–ª—è–µ–º —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    if processed_files:
        print(f"\nüóëÔ∏è  –£–¥–∞–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ({len(processed_files)})...\n")
        for file_path in processed_files:
            try:
                file_path.unlink()
                logger.info(f"–£–¥–∞–ª—ë–Ω: {file_path.name}")
            except Exception as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {file_path.name}: {e}")
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "="*50)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:")
    print("="*50)
    print(f"‚úÖ –§–∞–π–ª—ã –ø—Ä–æ–¥–∞–∂:    {stats['main_data']}")
    print(f"‚úÖ –§–∞–π–ª—ã —Ä–µ–∫–ª–∞–º—ã:   {stats['reklama']}")
    print(f"‚úÖ –§–∞–π–ª—ã —Å–∫–ª–∞–¥–∞:    {stats['storage']}")
    if stats['unknown'] > 0:
        print(f"‚ö†Ô∏è  –ù–µ–æ–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ:    {stats['unknown']}")
    print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤:  {len(processed_files)}")
    print("="*50 + "\n")